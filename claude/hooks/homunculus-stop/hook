#!/usr/bin/env bash
#
# Increment session count, update lastSession timestamp, generate a
# session summary markdown file for qmd indexing, summarise the
# conversation via LLM, and trigger the observer agent to process
# accumulated observations. Always exits 0 to never block session close.

# Note: errexit intentionally omitted so failures don't block session close.
set -o errtrace -o pipefail -o nounset

readonly HOMUNCULUS_DIR="${HOME}/.claude/homunculus"
readonly STATE="${HOMUNCULUS_DIR}/identity.json"
readonly OBS_DIR="${HOMUNCULUS_DIR}/observations"
readonly SESSIONS_DIR="${HOMUNCULUS_DIR}/sessions"
readonly CONVERSATIONS_DIR="${HOMUNCULUS_DIR}/conversations"
readonly LOG_FILE="${HOMUNCULUS_DIR}/logs/observer.log"
readonly LOCK_FILE="${HOMUNCULUS_DIR}/observer.lock"

[[ -f ${STATE} ]] || exit 0
command -v jq >/dev/null 2>&1 || exit 0

# Read the Stop hook payload for session metadata.
input=$(cat)
SESSION_CWD=$(echo "${input}" | jq -r '.cwd // empty' 2>/dev/null)
readonly SESSION_CWD
SESSION_ID=$(echo "${input}" | jq -r '.session_id // empty' 2>/dev/null)
readonly SESSION_ID

timestamp=$(date -u +%Y-%m-%dT%H:%M:%SZ)
tmp=$(mktemp)

if jq --arg ts "${timestamp}" \
  '.session_count += 1 | .last_session = $ts' \
  "${STATE}" >"${tmp}"; then
  mv "${tmp}" "${STATE}"
fi

# Generate session summary from observations accumulated during this session.
generate_session_summary() {
  mkdir -p "${SESSIONS_DIR}"

  local project_name
  project_name=$(basename "${SESSION_CWD:-unknown}")

  local file_ts
  file_ts=$(date -u +%Y-%m-%dT%H%M%SZ)
  local summary_file="${SESSIONS_DIR}/${file_ts}-${SESSION_ID:0:7}.md"

  # Extract tool usage stats and touched files from this session's observations.
  local session_obs="${OBS_DIR}/${SESSION_ID}.jsonl"
  local tools_json files_json
  if [[ -f ${session_obs} ]] && [[ -s ${session_obs} ]]; then
    tools_json=$(jq -rs '[.[].tool] | group_by(.) | map({(.[0]): length}) | add // {}' "${session_obs}" 2>/dev/null || echo '{}')
    files_json=$(jq -rs '[.[] | select(.context.file_name != null) | .context.file_name] | unique' "${session_obs}" 2>/dev/null || echo '[]')
  else
    tools_json='{}'
    files_json='[]'
  fi

  # Build YAML list of tools used (sorted by frequency, descending).
  local tools_yaml
  tools_yaml=$(echo "${tools_json}" | jq -r 'to_entries | sort_by(-.value) | map(.key) | .[]' 2>/dev/null)
  local tools_list=""
  if [[ -n ${tools_yaml} ]]; then
    tools_list=$(echo "${tools_yaml}" | paste -sd, - | sed 's/,/, /g')
  fi

  # Build list of files touched.
  local files_list
  files_list=$(echo "${files_json}" | jq -r '.[]' 2>/dev/null | sort -u | head -20)

  # Find the most recent previous session for this project (story threading).
  # Filter out the current summary file to avoid self-referencing loops.
  local continues_from=""
  local current_basename
  current_basename=$(basename "${summary_file}")
  if command -v qmd >/dev/null 2>&1; then
    continues_from=$(qmd search "project: ${project_name}" -c homunculus-sessions -n 2 --files 2>/dev/null |
      awk -F, '{print $3}' |
      sed "s|^qmd://homunculus-sessions/||" |
      while IFS= read -r candidate; do
        if [[ ${candidate} != "${current_basename}" ]]; then
          echo "${candidate}"
          break
        fi
      done)
  fi

  {
    echo "---"
    echo "date: ${timestamp}"
    echo "project: ${project_name}"
    echo "directory: ${SESSION_CWD:-unknown}"
    echo "session_id: ${SESSION_ID:0:7}"
    echo "type: session"
    echo "tools_used: [${tools_list}]"
    if [[ -n ${continues_from} ]]; then
      echo "continues_from: ${continues_from}"
    fi
    echo "---"
    echo ""
    echo "# Session: ${project_name}"
    echo ""
    echo "## Files touched"
    if [[ -n ${files_list} ]]; then
      while read -r f; do echo "- ${f}"; done <<<"${files_list}"
    else
      echo "- (none recorded)"
    fi
  } >"${summary_file}"
}

generate_session_summary 2>/dev/null || true

# Send a macOS notification. Failures are swallowed.
notify() {
  terminal-notifier \
    -title "Homunculus Observer" \
    -message "$1" \
    -sound default \
    -group "homunculus-observer" \
    2>/dev/null || true
}

# Promote instincts that meet all deterministic criteria to
# convictions, and revoke stale ones. Runs after the observer updates confidence/last_seen so
# decisions are based on fresh data. No LLM needed.
promote_mature_instincts() {
  local instincts_dir="${HOMUNCULUS_DIR}/instincts/personal"
  local convictions_dir="${HOMUNCULUS_DIR}/convictions"
  local now f promoted_count=0
  local confidence created last_seen created_ts last_seen_ts
  local action domain name basename_md conviction_file ts tmp
  local conf
  now=$(date +%s)

  mkdir -p "${convictions_dir}"

  for f in "${instincts_dir}"/*.md; do
    [[ -f ${f} ]] || continue
    grep -q "^promoted: true" "${f}" && continue

    confidence=$(sed -n 's/^confidence: *//p' "${f}" | head -1)
    created=$(sed -n 's/^created: *//p' "${f}" | head -1)
    last_seen=$(sed -n 's/^last_seen: *//p' "${f}" | head -1)

    [[ -n ${confidence} && -n ${created} && -n ${last_seen} ]] || continue

    # Confidence >= 0.75
    awk -v c="${confidence}" 'BEGIN{exit(!(c+0 >= 0.75))}' || continue

    # Created >= 14 days ago (survived 2+ decay cycles).
    created_ts=$(date -j -f "%Y-%m-%dT%H:%M:%SZ" \
      "${created}" +%s 2>/dev/null) || continue
    ((now - created_ts >= 14 * 86400)) || continue

    # Last seen within 7 days (still actively relevant).
    last_seen_ts=$(date -j -f "%Y-%m-%dT%H:%M:%SZ" \
      "${last_seen}" +%s 2>/dev/null) || continue
    ((now - last_seen_ts <= 7 * 86400)) || continue

    action=$(sed -n 's/^action: *"*//p' "${f}" | sed 's/"$//' | head -1)
    [[ -n ${action} ]] || continue
    domain=$(sed -n 's/^domain: *//p' "${f}" | tr -d '"' | head -1)
    name=$(basename "${f}" .md | sed 's/^[^-]*-//')
    basename_md=$(basename "${f}")
    conviction_file="${convictions_dir}/${basename_md}"

    {
      echo "---"
      echo "name: ${name}"
      echo "action: \"${action}\""
      echo "domain: ${domain:-general}"
      echo "promoted_at: $(date -u +%Y-%m-%dT%H:%M:%SZ)"
      echo "source_instinct: ${basename_md}"
      echo "---"
    } >"${conviction_file}"

    # Mark instinct as promoted (scoped to frontmatter block).
    sed -i '' '/^---$/,/^---$/{
      /^last_seen:/a\
promoted: true\
promoted_to: ~/.claude/homunculus/convictions/'"${basename_md}"'
    }' "${f}"

    promoted_count=$((promoted_count + 1))
  done

  if ((promoted_count > 0)); then
    ts=$(date -u +%Y-%m-%dT%H:%M:%SZ)
    tmp=$(mktemp)
    if jq --arg ts "${ts}" '.last_promotion = $ts' \
      "${STATE}" >"${tmp}"; then
      mv "${tmp}" "${STATE}"
    fi
    echo "[$(date -Iseconds)] Promoted ${promoted_count} instinct(s) to convictions" >>"${LOG_FILE}"
    notify "Promoted ${promoted_count} instinct(s) to convictions"
  fi

  # Revoke stale convictions where the underlying instinct has decayed
  # below 0.40. The instinct stays at its floor so it can be re-promoted
  # if the pattern resurfaces.
  for f in "${instincts_dir}"/*.md; do
    [[ -f ${f} ]] || continue
    grep -q "^promoted: true" "${f}" || continue

    conf=$(sed -n 's/^confidence: *//p' "${f}" | head -1)
    [[ -n ${conf} ]] || continue
    if awk -v c="${conf}" 'BEGIN{exit(!(c+0 < 0.40))}'; then
      basename_md=$(basename "${f}")
      conviction_file="${convictions_dir}/${basename_md}"

      rm -f "${conviction_file}"

      # Scoped to frontmatter to avoid clobbering body content.
      sed -i '' '/^---$/,/^---$/{
        /^promoted: true$/d
        /^promoted_to:/d
      }' "${f}"

      name=$(basename "${f}" .md | sed 's/^[^-]*-//')
      echo "[$(date -Iseconds)] Revoked stale conviction: ${name} (confidence ${conf})" >>"${LOG_FILE}"
      notify "Revoked stale conviction: ${name}"
    fi
  done
}

# Run the observer agent to process accumulated observations.
# Backgrounded so it doesn't block session close.
run_observer() {
  # Homebrew may not be on PATH in backgrounded processes.
  export PATH="/opt/homebrew/bin:/usr/local/bin:${PATH}"

  # Signal to the observe hook that this is the observer agent, not a
  # regular session, so it skips logging (avoids feedback loop).
  export HOMUNCULUS_OBSERVER=1

  # Prevent concurrent runs (rapid session closes, manual triggers).
  # If a lock exists, check whether the holder is still alive. Stale
  # locks from crashed observer processes would block all future runs.
  if [[ -f ${LOCK_FILE} ]]; then
    local stale_pid
    stale_pid=$(cat "${LOCK_FILE}" 2>/dev/null)
    if [[ -n ${stale_pid} ]] && kill -0 "${stale_pid}" 2>/dev/null; then
      return
    fi
    # Holder is dead, reclaim the lock.
    rm -f "${LOCK_FILE}"
    echo "[$(date -Iseconds)] Reclaimed stale lock from PID ${stale_pid}" >>"${LOG_FILE}"
  fi
  if ! (
    set -o noclobber
    echo $$ >"${LOCK_FILE}"
  ) 2>/dev/null; then
    return
  fi
  trap 'rm -f "${LOCK_FILE}"' EXIT

  local count
  count=$(cat "${OBS_DIR}"/*.jsonl 2>/dev/null | wc -l | tr -d ' ')
  [[ ${count} -gt 0 ]] || return

  local start_time
  start_time=$(date +%s)

  {
    echo ""
    echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
    echo "[$(date -Iseconds)] Processing ${count} observations"
    echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
  } >>"${LOG_FILE}"

  # The agent reads per-session observation files, clusters patterns, and
  # writes instinct files. It archives processed files on success.
  if claude -p \
    --agent homunculus-observer \
    --add-dir "${HOMUNCULUS_DIR}" \
    --allowedTools "Read" "Write" "Bash" "Grep" \
    --no-session-persistence \
    <<<"Process ${count} pending observations from ${OBS_DIR}/ directory." \
    >>"${LOG_FILE}" 2>&1; then
    echo "[$(date -Iseconds)] Finished in $(($(date +%s) - start_time))s" >>"${LOG_FILE}"
    promote_mature_instincts 2>>"${LOG_FILE}" || true
  else
    echo "[$(date -Iseconds)] Failed in $(($(date +%s) - start_time))s" >>"${LOG_FILE}"
    notify "Failed processing ${count} observations"
  fi
}

# Summarise the session conversation via LLM and save for qmd indexing.
# Backgrounded since the LLM call takes a few seconds.
summarise_conversation() {
  export PATH="/opt/homebrew/bin:/usr/local/bin:${PATH}"
  mkdir -p "${CONVERSATIONS_DIR}"

  # Derive the path to this session's conversation JSONL.
  local escaped_cwd
  escaped_cwd=$(echo "${SESSION_CWD}" | tr '/' '-')
  local jsonl="${HOME}/.claude/projects/${escaped_cwd}/${SESSION_ID}.jsonl"
  [[ -f ${jsonl} ]] || return

  # Extract human messages and assistant text blocks from the JSONL.
  local dialogue
  dialogue=$(jq -r '
    (.message // empty) |
    if .role == "user" and (.content | type) == "string" and (.content | test("\\S"))
    then "Human: " + .content
    elif .role == "assistant" and (.content | type) == "array"
    then .content[] | select(.type == "text" and (.text | test("\\S"))) | "Assistant: " + .text
    else empty
    end
  ' "${jsonl}" 2>/dev/null)
  [[ -n ${dialogue} ]] || return

  # Truncate to stay within haiku's context.
  dialogue=$(echo "${dialogue}" | head -c 80000)

  local project_name file_ts summary_file prompt_file summary
  project_name=$(basename "${SESSION_CWD:-unknown}")
  file_ts=$(date -u +%Y-%m-%dT%H%M%SZ)
  summary_file="${CONVERSATIONS_DIR}/${file_ts}-${SESSION_ID:0:7}.md"

  # Build the prompt in a temp file to avoid shell escaping issues
  # with the raw dialogue content.
  prompt_file=$(mktemp)
  trap 'rm -f "${prompt_file}"' RETURN
  {
    cat <<'PROMPT'
Summarise this Claude Code conversation concisely. Structure:

## Goals
What the user wanted to achieve.

## Decisions
Key choices made and their rationale.

## Outcomes
What was accomplished, what remains.

Keep it under 300 words. Focus on decisions and rationale, not individual tool calls or code.

<conversation>
PROMPT
    echo "${dialogue}"
    echo "</conversation>"
  } >"${prompt_file}"

  summary=$(MAX_THINKING_TOKENS=0 claude -p \
    --model haiku \
    --no-session-persistence \
    --tools '' \
    --disable-slash-commands \
    --setting-sources '' \
    --system-prompt '' \
    <"${prompt_file}" 2>/dev/null)
  [[ -n ${summary} ]] || return

  {
    echo "---"
    echo "date: ${timestamp}"
    echo "project: ${project_name}"
    echo "directory: ${SESSION_CWD:-unknown}"
    echo "session_id: ${SESSION_ID:0:7}"
    echo "type: conversation"
    echo "---"
    echo ""
    echo "# Conversation: ${project_name}"
    echo ""
    echo "${summary}"
  } >"${summary_file}"

  echo "[$(date -Iseconds)] Summarised conversation to $(basename "${summary_file}")" >>"${LOG_FILE}"
}

# Trigger observer if there are observation files to process.
if compgen -G "${OBS_DIR}/*.jsonl" >/dev/null 2>&1; then
  run_observer </dev/null &
fi

# Summarise conversation in the background.
if [[ -n ${SESSION_ID} && -n ${SESSION_CWD} ]]; then
  summarise_conversation </dev/null &
fi

exit 0
